\section{Superiority of Relgo in Optimization}
\label{sec:theoretical-analysis}

In this section, we prove that graph optimizers have better performance than relational optimizers on graph query optimization.
It confirms that translating graph queries into relational queries to be optimized with relational optimizers is not a good choice.

As one of the most widely adopted optimizers for relational databases, we use Calcite \cite{calcite,columbia} as a representative of relational optimizers and analyze its efficiency.
For relgo, Calcite is also used as the relational optimization module.
Meanwhile, GLogue \cite{GLogS} is applied as the graph optimization module.

For simplicity, we focus on the problem of join order optimization in this section, and a simple case is first considered.
That is, all the tables in the query represent vertices or edges.
The tables that can represent vertices or edges are called graph tables, and the graph formulated by these graph tables are called a query graph.
Then, assuming that there are $n + m$ graph tables joined together, with $n$ tables representing vertices and $m$ tables representing edges.
Suppose that there are $t$ implementation methods for join.
Noramlly, various kinds of joins are supported in relational databases, e.g., hash join, merge join, and index join.
Consequently, it is supposed that $t \geq 2$.
The complexities of optimizing the join order with Calcite and relgo are analyzed respectively as follows.
For simplicity, the time complexities are estimated with the number of physical plans generated by the optimizers.


\begin{theorem}
    \label{theorem:complexity-of-calcite}
    The time complexity of join order optimization with Calcite is at least $O(4^{m+n-1})$.
\end{theorem}
\begin{proof}
    The $n + m$ tables joined together can form a graph, where the tables represent vertices in the graph, and if there is a join condition w.r.t.~two tables, there is an edge between these two tables.
    Then, the complexity of join order optimization with Calcite can be estimated as the number of possible physical plans that can be generated.
    
    To avoid cross product, everytime two tables are joined together, there should be join conditions w.r.t.~them.
    Therefore, the join order can be represented as a spanning tree in the graph.
    By computing the number of physical plans can be generated according to each spanning tree, the total number of physical plans can be obtained.
    %%%
    %However, same phyical plans may be obtained according to different spanning trees.
    %For example, suppose a graph is a rectangle with four vertices and four edges.
    %It may be constructed for a query like:
    %\begin{equation*}
    %    \begin{split}
    %        \text{SELECT}\hspace{.5em} ... & \hspace{.5em}\text{FROM}\hspace{.5em} A, B, C, D \hspace{.5em}\text{WHERE}\hspace{.5em} A.a1 = B.b1 \\ 
    %        & \hspace{.5em}\text{AND}\hspace{.5em} B.b2 = C.c1 \hspace{.5em}\text{AND}\hspace{.5em} C.c2 = D.d1 \hspace{.5em}\text{AND}\hspace{.5em} D.d2 = A.a2. 
    %    \end{split}
    %\end{equation*}
    %Then, the spanning tree with edges \{AB, BC, CD\} and the one with edges \{AB, BC, AD\} can generate the same physical plans.
    %Consequently, the summation of the number of physical plans corresponding to all the spanning trees is larger than the actual number of physical plans.
    In this proof, we compute the number of physical plans for one spanning tree, and this number is the lower bound of the number of physical plans that can be generated.

    We start with a spanning tree with $k$ edges ($k \geq 1$), which has only one leaf node (i.e., it is a path).
    Then, the number of logical plans corresponding to the spanning tree is
    \begin{equation*}
        \begin{split}
            c_l(k) & = 2 * (c(0)c(k-1) + c(1)c(k-2) + \cdots + c(k-1)c(0)) \\
            & = 2\Sigma_{i=0}^{i=k-1}c(i)c(k-1-i), \\
            & \text{where } c_l(0) = 1.
        \end{split}
    \end{equation*}
    With the generating function, it is obtained that 
    \begin{equation*}
        \begin{split}
            c_l(k) & = \frac{2^k}{k+1}C(2k, k) \geq \frac{2^k}{k+1}\frac{2k \times \cdots \times (k+1)}{k \times \cdots \times 1} \\
            & \geq \frac{2^k}{k+1}2^{k-1}(k+1) = \frac{4^k}{2}
        \end{split}
    \end{equation*}
    %Since $k$ is the number of edges, and $k = m + n - 1$ in the spanning tree.
    %Thus, the number of logical plans w.r.t.~a spanning tree is 
    %\begin{equation*}
    %    \frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1) \geq \frac{4^{m+n-1}}{m+n}.
    %\end{equation*}

    For any spanning tree $T$ with $k = m + n - 1$ edges, denote the longest path in the tree by $p_1$, and its length is $P_1 = |p_1|$.
    By removing the path (i.e., edges in $p_1$) from $T$, we can obtain a new subgraph $T_1$.
    Similarly, the longest path in $T_1$ that intersects with the already removed paths (i.e., $p_1$) is found and denoted by $p_2$, with $P_2 = |p_2|$.
    After that, $p_2$ is removed from $T_1$ and subgraph $T_2$ is obtained.
    For $p_1$ and $p_2$, since they are both paths, the numbers of logical plans corresponding to them are $c_l(P_1)$ and $c_l(P_2)$, respectively.
    Without loss of generality, suppose $p_1$ and $p_2$ intersects at vertex $v_i$, and then, $v_i$ appears in each logical plan corresponding to $p_1$.
    Then, by replacing $v_i$ with the plans corresponding to $p_2$, respectively, $c(p_1 \cup p_2) \geq c_l(P_1)c_l(P_2)$ is obtained, where $c(t)$ is the number of logical plans corresponding to tree $t$ and $c(t) = c_l(k)$ when $t$ is a path with $k$ edges.

    As $T$ is a tree, by repeatedly finding and removing the paths as above, all the edges in $T$ are finally removed.
    Let the number of paths removed be $s$, we have 
    \begin{equation*}
        \begin{split}
            c(T) & = c(p_1 \cup \cdots \cup p_s) \geq c_l(P_1) \cdots c_l(P_s) \\
            & \geq \frac{4^{P_1 + \cdots + P_s}}{2^s} = \frac{4^{m + n - 1}}{2^s} \geq 2^{m+n-1}.
        \end{split}
    \end{equation*}
    
    %Thus, the number of logical plans w.r.t.~a spanning tree is 
    %\begin{equation*}Æ’
    %    \frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1) \geq \frac{4^{m+n-1}}{m+n}.
    %\end{equation*}
    

    Thus, the number of physical plans is at least $2^{m+n-1}t^{m+n-1} \geq 4^{m+n-1}$, so is the complexity of join order optimization with Calcite.
   
    In conclusion, Theorem \ref{theorem:complexity-of-calcite} is correct.
\end{proof}

\begin{lemma}
    \label{lemma:upper-bound-of-calcite}
    Given $z$ tables, the time complexity of join order optimization with Calcite has an upper bound of $O(\frac{(2z-2)!}{(z-1)!}t^{z-1})$.
\end{lemma}
\begin{proof}
    The upper bound of the time complexity of join order optimization is achieved when there is a condition between any two of the $z$ tables.
    Because at that time, the tables can be joined in any order.

    Since each join order corresponds to a full binary tree with $2z-1$ nodes, the problem is to count the number of possible full binary trees.
    Similar to Catalan number, the number of full binary trees is $O(C(2z-2, z-1) - C(2z-2, z))$.
    For each full binary tree, there are $z!$ ways to set the leaf nodes. 
    Then, the number of generated physical plans is $O(\frac{(2z-2)!}{(z-1)!}t^{z-1})$.
\end{proof}


\begin{theorem}
    \label{theorem:complexity-of-glogue}
    The time complexity of join order optimization with relgo is smaller than $3^n$ if all the tables participant in join are graph tables.
\end{theorem}
\begin{proof}
    Since the $n + m$ tables are graph tables, relgo optimizes the join order with the graph optimization module, i.e., GLogue.

    As GLogue ensures worst-case optimality and the considered patterns are all induced subgraphs, the time complexity of join order optimization with GLogue is not related to the number of edges (i.e., $m$).
    Since the join order optimization problem is reduced to a variant of the shortest path problem, the time complexity is $O(\mathcal{E})$, where $\mathcal{E}$ is the number of edges in GLogue.
    In detail, 
    \begin{equation*}
        \begin{split}
            %O(\mathcal{E}) & = C(n, n-1)*(2^{n-1}-1) + C(n, n-2) * (2^{n-2}- 1) \\
            %& + \cdots + C(n, 1) * (2^1 - 1) \\
            O(\mathcal{E}) & = \Sigma_{i=1}^{i=n-1}C(n, i)(2^i - 1) = 3^n - 2^{n+1} +1 < 3^n.
        \end{split}
    \end{equation*}
    
    In conclusion, Theorem \ref{theorem:complexity-of-glogue} is correct.

\end{proof}

Based on the complexity analysis in Theorem \ref{theorem:complexity-of-calcite} and Theorem \ref{theorem:complexity-of-glogue}, it is found that when the tables represent vertices and edges, 
\begin{equation*}
    \begin{split}
        \frac{\text{Time Complexity of Calcite}}{\text{Time Complexity of relgo}} & > O(\frac{4^{m+n-1}}{3^n}) = O(4^{m-1}(\frac{4}{3})^n).
    \end{split}
\end{equation*}
Therefore, it suggests that relgo is exponentially faster than Calcite for graph-like join order optimization.
The results also indicate that integrating graph optimizers into relational optimizers can improve the efficiency of join order optimization significantly.


Then, to be more general, if there are some tables that cannot represent vertices or edges, the order of such tables cannot be optimized only with graph optimizers, and the problem becomes more complicate.
For example, suppose five tables form a clique, and then these tables cannot be vertices or edges in a graph.
According to relgo, the join order of the graph tables are optimized with GLogue.
The plan obtained by GLogue is considered as a table and optimized together with the left tables (which are not graph tables) by Calcite.
Without the loss of generality, the query graph formulated by the graph tables are assumed to be connected.
When the query graph is not connected, only one connected component of the query graph is optimized with GLogue.
The other tables are not considered as graph tables and are optimized with Calcite.
The efficiency of relgo and Calcite are compared with the following lemma and theorem.

%Specifically, according to the dataflow shown in Fig.~\ref{fig:dataflow}, the join order of these left tables are optimzed by relational optimizers such as Calcite.
%Let the number of left tables be $q$, and together with the table obtained by the join of the tables optimized with graph optimizer, Calcite needs to optimize the join order among $q + 1$ tables.

\iffalse
When $q = 0$, all the tables represent vertices or edges, and the time complexity of relgo is exponentially smaller than that of Calcite as analyzed as above.

When $q = 1$, only one table (saying $T_1$) does not represent a vertex or an edge, and Calcite optimizes the join between two tables.
One of these two tables is $T_1$, and the other is the table obtained by the join of the tables optimized with the graph optimizer.
Then, we have
\begin{equation*}
    \begin{split}
        \frac{\text{Time Complexity of Calcite}}{\text{Time Complexity of relgo}} > \hspace{-12em} & \\
        & \frac{\frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1)t^{m + n - 1}}{3^{\hat{n}} + \frac{(2s)!}{(s)!}t^{s}} \\
        & = \frac{\frac{2^{m+n-1}}{m+n}C(2m+2n-2, m+n-1)t^{m + n - 1}}{3^{\hat{n}} + 2} >> 1,
    \end{split}
\end{equation*}
where $\hat{n}$ is the number of tables representing vertices.
It indicates the superiority of the converged JOPT.

When $s = m + n - 1$ or $p = m + n$, at most one table can represent vertices or edges, and the converged JOPT degenerates to Calcite, and has the same efficiency as it.
A typical example is when there is a condition between any two of these $m + n$ tables.

The results show that the converged JOPT is always superior to relational JOPTs.
To be more specific, we prove the superiority of the converged JOPT more theoretically.
\fi

\begin{lemma}
    \label{lemma:join-spliter}
    Let $\text{JN}_c(V_s)$ represent the number of possible physical plans of joining tables in table set $V_s$ with Calcite.
    Suppose $n$ tables (denoted as table set $V$) are joined, and $V = (V_1 - u) \cup V_2$, $V_1 \cap V_2 = \emptyset$.
    Specifically, $u \in V_1$ is a table representing the results of joining the tables in $V_2$.
    For each table $t_2 \in V_2$, if there is a join condition between $t_2$ and a table $v$ in $V_1$, the same join condition exists between $u$ and $v$.
    Then, we have $\text{JN}_c(V) \geq \text{JN}_c(V_1) * \text{JN}_c(V_2)$.
\end{lemma}
\begin{proof}
    For a physical plan generated by joining tables in $V_1$ (denoted as $p_1$) and a plan generated by joining tables in $V_2$ (denoted as $p_2$), by replacing $u$ in $p_1$ with $p_2$, we can generate a physical plan of joining tables in in $V$.
    Besides, since the tables in $p_1$ cannot be interchanged with tables in $p_2$, more physical plans can be generated by joining tables in $V$.
    In conclusion, we have $\text{JN}_c(V) \geq \text{JN}_c(V_1) * \text{JN}_c(V_2)$.
\end{proof}

\begin{theorem}
    \label{theorem:complexity-of-converged-jopt}
    The time complexity of join order optimization with relgo is always smaller than that with Calcite.
\end{theorem}
\begin{proof}
    Denote the set of graph tables by $R$, denote the set of other tables by $S$, and denote the table obtained by joining the tables in $R$ by $T_r$.
    Then, we have $S_r = S \cup T_r$.
    Moreover, let $s = |S|$ and $r = |R|$ represent the size of table sets $S$ and $R$, respectively, and let $r_v$ be the number of tables in $R$ representing vertices.
    Denote the number of possible physical plans of joining tables in $R$ with GLogue by $\text{JN}_g(R)$.
    
    Specifically, according to Theorem \ref{theorem:complexity-of-calcite} and Theorem \ref{theorem:complexity-of-glogue}, we have $4^{r - r_v -1}(\frac{4}{3})^{r_v}\text{JN}_g(R) < \text{JN}_c(R)$.
    % $\text{JN}_g(R) < 3^{r_v} \leq 4^{r-1} \leq \text{JN}_c(R)$.
    Note that $T_r$ corresponds to $u$ in Lemma \ref{lemma:join-spliter}.
    Based on Lemma \ref{lemma:join-spliter}, we have $\text{JN}_c(S \cup R) \geq \text{JN}_c(S_r) * \text{JN}_c(R) \geq 4^{r - r_v -1}(\frac{4}{3})^{r_v} * \text{JN}_c(S_r) * \text{JN}_g(R)$.
    In conclusion, Theorem \ref{theorem:complexity-of-converged-jopt} is correct, and relgo always has exponentially smaller time complexity than Calcite.
\end{proof}

There are mainly three reasons contributing to the efficient performance of the relgo:
(1) Different implementations of the join operators are not considered in relgo, because the neighbors of vertices can be efficiently accessed with the graph indices.
(2) In relgo, only the number of vertices influence the complexity of join order optimization, while the complexity is determined by both the numbers of vertices and edges in Calcite.
(3) relgo can take isomorphism into consideration in optimization and further reduce the search space, while Calcite does not consider optimization related to isomorphism.
